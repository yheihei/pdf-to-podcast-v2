# PDF/テキストからポッドキャスト風音声を生成するツール（MVP）PRD

## 目的と範囲

このドキュメントは、PDFドキュメントまたはテキストから**ポッドキャスト風の音声ファイル**を作成するPython製ツールの製品要件を示します。ユーザーは長文のPDFやテキストコンテンツを入力し、本ツールを使って1人語りのナレーション音声（ポッドキャスト形式）を自動生成できます。MVP（Minimum Viable Product）として、**必要最小限の機能**に絞り、過剰な要件は含めません。

**本MVPのスコープ:**

* 単一話者の音声コンテンツ生成（1人によるナレーション形式）。
* 入力から音声出力までの基本的な4段階の処理（入力解析、コンテンツ分割、脚本生成、音声合成）。
* コマンドライン上での動作（CLIツールとして各処理を実行可能）。
* 日本語を含むテキストコンテンツへの対応（入力言語をそのまま音声化）。

**除外（今回扱わない事項）:**

* 複数話者の対話型スクリプトや複数音声の合成（会話形式のポッドキャストは対象外）。
* 入力テキストの翻訳（入力と異なる言語への変換は行わない）。
* BGMの追加や高度な音声編集機能。
* GUI（グラフィカルユーザーインターフェース）の提供（CLI操作のみ）。

## ソリューション概要

本ツールは以下の4つのフェーズで音声ファイル生成を行います。それぞれのフェーズは独立したCLIコマンドとして実行可能であり、途中のフェーズから再開することもできます。全体の処理の流れを次に示します。

1. **入力フェーズ** – PDFまたはテキストファイルを読み込み、テキスト抽出を行います（PDFの場合は指定ページ範囲のみ抽出可能）。
2. **コンテンツ分割フェーズ** – コンテンツが長大な場合、LLM（Geminiモデル）を用いて内容上の自然な区切り（章や節など）でテキストを分割します。分割後、それぞれの部分を個別のテキストファイルとして保存します。
3. **脚本生成フェーズ** – 各分割テキストに対し、LLM（Geminiモデル）で**口語調の一人語り用脚本**に変換します。生成された脚本テキストもファイルに保存します。
4. **音声合成フェーズ** – 脚本テキストをもとに、GoogleのGenerative AI（Gemini API）のTTS機能を使って音声データを生成します。指定した話者スタイル・声質で合成し、最終的にMP3形式の音声ファイルとして書き出します。各パートが約4分程度の音声長になるように調整します。

各フェーズで生成された中間ファイル（抽出テキスト、分割テキスト、脚本テキストなど）は保存されるため、途中のフェーズから再実行したり、出力を確認したりできます。また、各処理過程でログを記録し、処理の追跡やエラー解析を容易にします。

## 機能要件

### 入力フェーズ（PDF/テキスト読み込み）

* **PDF入力:** ユーザーはPDFファイルを指定して入力できます。オプションで開始ページと終了ページを指定し、その範囲のページのみを読み込み対象とします。指定がない場合はPDF全体を処理します。
* **テキスト入力:** テキストファイル（.txt, .md）を指定することも可能です。この場合はファイル全体のテキストをそのまま使用します。
* **PDFテキスト抽出:** PDFからのテキスト抽出にはPythonライブラリ（例：PyPDFやpdfplumber等）を使用します。レイアウト崩れや不要な改行の除去など、**脚本化しやすいテキスト**になるよう可能な範囲で整形します。
* **出力:** 抽出もしくは入力されたテキストは、この後の処理で利用するため一時テキストファイル（例:`input_text.txt`）に保存します。

### コンテンツ分割フェーズ（長文コンテンツの分割）

* **目的:** 長大なコンテンツを扱う場合、適切なサイズにテキストを分割し、後続の処理（脚本化・音声化）の精度と効率を保ちます。特に音声合成では一度に扱えるテキスト長に制限があるため、分割は重要です。
* **分割方法:** GeminiのLLMモデルを利用し、内容の論理構造に沿って**自然な区切り**位置を判断します。例えば、「章・節が変わるタイミング」「トピックが切り替わる箇所」で区切ることで、各チャンク（塊）が独立した話題やセクションとして完結するようにします。

  * *実装アプローチ:* 抽出テキストをLLMに渡し、「本文を約○○字（音声で数分程度）ごとに区切りたい。自然な切れ目を提案してください」といったプロンプトを与え、分割ポイント（例：段落番号やキーワード）を生成します。
* **チャンクサイズ:** 1チャンクあたりのテキスト量は、音声にしたとき**約4分程度**の長さを目安とします（おおよそ500～600語程度が目安）。これにより、後述の音声ファイルが扱いやすい長さになります。
* **出力:** 分割された各チャンクのテキストを別個のファイルに保存します（例：`chunk_1.txt`, `chunk_2.txt`, ...）。チャンクが1つ（短いコンテンツ）の場合は、このフェーズでの分割処理はスキップされ、そのまま次の脚本化フェーズへ進みます。

### 脚本生成フェーズ（話し言葉スタイルへの変換）

* **目的:** 各チャンクのテキストを、**1人が自然に話す口調の脚本**に変換します。論文調・書籍調の文章であれば、聞き手に分かりやすい話し言葉に言い換えるなど、ポッドキャストで朗読・解説する形式の原稿にします。
* **LLMによる脚本化:** Geminiなど指定のLLMモデルを使用し、各チャンクテキストから話し言葉のスクリプトを生成します。プロンプト例: 「以下のテキスト内容を、一人称で口語的なナレーション台本に書き直してください。」などとして、カジュアルすぎず聞き取りやすい文体で出力します。

  * **スタイル:** 基本はフォーマルすぎない説明口調を想定します。必要に応じて、LLMへの指示で語り口調のトーン（例えば「親しみやすく」「落ち着いた口調で」など）を調整できます。
* **内容の忠実性:** 脚本化後も**元の内容・意味を損なわない**ことが重要です。専門用語の簡略な説明を追加する程度は許容しますが、MVP段階では大きな意図変更や脚色は行いません。基本は原文に忠実な要約・言い換えに留めます。
* **出力:** 生成された脚本テキストは各チャンクごとにファイル保存します（例：`script_1.txt`, `script_2.txt`, ...）。ユーザーはこのテキストを確認し、必要であれば手動で修正してから次の音声合成フェーズへ進むことも可能です（MVPでは手動修正は必須ではありませんが、オプションとして許容）。

### 音声合成フェーズ（TTSによる音声化）

* **目的:** 脚本テキストを実際の音声データに変換し、ポッドキャスト風の音声ファイルを作成します。
* **音声合成エンジン:** GoogleのGenerative AI API（GeminiモデルのTTS機能）を利用します。GoogleのGemini APIによるTTSは**スタイルやアクセント、話速、トーンを自然言語で細かく制御可能**であり、正確なテキスト読み上げに適しているため。MVPではシングルスピーカー（単一話者の声）で出力します。
* **話者の指定:** 出力音声の話者は、Gemini TTSが提供する**プリセット音声**から選択します（例: 日本語の男性/女性のナレーター音声など）。スタイル（声の調子や感情表現）も指定可能であれば、.envやオプション引数で設定できるようにします（例：「落ち着いたトーン」「明るい口調」などの指定）。
* **実装:** `google.genai` パッケージを用い、Geminiの音声モデルにテキストを渡して音声データ（PCM）を取得します。その際、リクエストの**応答モダリティ**を "audio" に設定し、希望の音声名・スタイルを `SpeechConfig` で指定します（Gemini 2.5系のTTSモデルを使用予定）。

  * 取得した音声データは一旦WAVまたはPCMバイナリとして受け取り、所定のサンプルレート（例: 24kHz）でWaveファイルに保存します。その後、FFmpegやPythonライブラリを使って**MP3形式**にエンコードします（もしくは直接MP3で保存可能な場合は省略）。
* **出力:** 各脚本に対応する音声ファイル（例：`output_1.mp3`, `output_2.mp3`, ...）を生成します。複数のチャンクがある場合、出力も複数のMP3ファイルになります。各音声ファイルは約4分程度の長さとなり、長すぎず取り扱いやすいサイズになります。必要に応じて後工程でこれらを連結し一本の音声にまとめることも可能ですが、MVPでは自動連結は行わず**各チャンク音声を個別ファイルとして提供**します。

## CLI設計と設定

* **CLI操作:** 各フェーズはコマンドラインから個別に起動できるようにします。一つのPythonスクリプトでサブコマンド（例：`input`, `split`, `script`, `synthesize`）として実装するか、フェーズごとに別のスクリプト（例：`phase1_input.py` 等）を用意する形を想定しています。

  * *例:*

    * フェーズ1実行: `python tool.py input --pdf book.pdf --start 10 --end 20`
    * フェーズ2実行: `python tool.py split --infile input_text.txt`
    * フェーズ3実行: `python tool.py script --indir chunks/`
    * フェーズ4実行: `python tool.py synthesize --indir scripts/ --voice JapaneseFemale1`
* **途中再開:** 例えばフェーズ3まで完了後に内容を微修正した場合、フェーズ4（音声合成）だけを再実行するといった使い方ができます。各フェーズは必要な入力ファイルが存在すればそれを用いて処理を開始します（既定のファイルパスやディレクトリ構成をドキュメント化しておく）。
* **環境設定 (.env):** LLMモデル名やAPIキーなどの機密情報、設定値は`.env`ファイルから読み込むようにします。各フェーズで使用するモデルを個別に指定可能にします。例えば:

  * `MODEL_SPLIT=gpt-3.5-turbo` （またはGeminiモデル名）
  * `MODEL_SCRIPT=gemini-2.5-chat`
  * `MODEL_TTS=gemini-2.5-tts`
  * `GENAI_API_KEY=...`（Google Generative AI APIキー）
  * `VOICE_NAME=...`（デフォルトの音声合成に使うプリセット声名称）
* **設定の上書き:** ユーザーがCLI引数でモデル名や音声名を指定した場合は、.envの値よりCLI指定を優先させます。指定が無ければ.envのデフォルト値を使います。これにより柔軟性を持たせつつ、安全にキー情報などを管理します。

## ログ記録とエラーハンドリング

* **ログ出力:** 全フェーズを通じて、進行状況や結果をログファイルに記録します。Pythonの`logging`モジュールを利用し、INFOレベルで主要なイベント（開始・完了や生成ファイル名）、DEBUGレベルで詳細な情報（分割ポイントやAPIレスポンスの一部など）を残します。

  * ログ例: `2025-06-25 14:10:32 [INFO] Phase3: script_2.txt generated (800 chars)`
* **エラーハンドリング:** 各フェーズで発生しうるエラーを捕捉し、ユーザーにわかりやすいメッセージを表示します。同時にログにもスタックトレース等を出力します。想定例: PDF読み込み失敗、LLM API呼び出し失敗（タイムアウトや認証エラー）、TTS合成失敗等。
* **リトライ:** 必要に応じ、LLM APIやTTS APIの呼び出しは一定回数のリトライを行います（MVPでは1回程度の簡易リトライ実装を検討）。長いテキストの場合はチャンク単位での処理なので、失敗したチャンクのみ再実行することもできます。
* **ログ管理:** ログファイルは日時付きで出力し、過去ログが蓄積しすぎないようローテーション（一定サイズや世代数で古いログを削除）する仕組みを導入します（必要最低限で良いので、MVPでは手動クリアでも可）。

## 出力と成果物

本ツールの実行により、以下の成果物が生成されます。

* **音声ファイル (MP3)**: 最終成果物として各チャンクごとにMP3形式の音声ファイルが出力されます。ファイル名は元入力名やチャンク番号に基づいて付与されます（例：`book_part1.mp3`, `book_part2.mp3`）。音声は指定したスタイル・声で読み上げられたポッドキャスト風ナレーションです。
* **音声長さ（約4分単位）:** 出力された音声は、日本語ナレーションの場合**1ファイルあたり約4分程度**の長さになるよう調整されています。これにより、長すぎず扱いやすい長さでコンテンツを消費できます。非常に短い入力の場合はこの限りではありませんが、長大な入力は複数ファイル（エピソード）に分割されます。
* **整えられた脚本テキスト:** 音声合成の元となった脚本テキストファイル（各チャンク分）が生成され、保存されています。これらは**音声化に適した形に整備済み**であり、人間が読み上げる場合にもそのまま台本として利用できる品質を目指しています。ユーザーは必要に応じてこのテキストを微調整できます。
* **ファイル出力の完備:** 中間生成物も含め、全ての出力データはファイルとして明示的に書き出されます。入力テキスト抽出結果（`input_text.txt`）、分割後テキスト（`chunk_*.txt`）、脚本テキスト（`script_*.txt`）、音声ファイル（`*.mp3`）がそれぞれ保存され、ユーザーは各段階の結果を確認・再利用可能です。

以上が、本MVPにおけるPDF/テキストからポッドキャスト風音声ファイル生成ツールの製品要件です。今後、ユーザーフィードバックに基づき多声対応や自動編集機能など拡張の可能性はありますが、まずは上記コア機能に焦点を当てて実装を行います。各要件が満たされていることを確認しつつ、シンプルで確実に動作するプロトタイプの完成を目指します。

**参考文献:**

* Google AI Developers: *Speech generation (text-to-speech) – Gemini API*（音声合成のスタイル制御や用途に関する解説）
